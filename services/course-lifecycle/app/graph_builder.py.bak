from typing import List, Dict, Optional
import logging
from .graph_schema import CourseGraph, ModuleNode, TopicNode, SubtopicNode, SlideNode
from .models import Course, TopicGenerationJob
import uuid

logger = logging.getLogger(__name__)

class GraphBuilder:
    def __init__(self, course: Course, topic_jobs: List[TopicGenerationJob]):
        self.course = course
        self.jobs_map = {
            f"{j.module_id}::{j.topic_id}": j 
            for j in topic_jobs if j.status in ["GENERATED", "VERIFIED", "APPROVED"]
        }
        self.existing_graph = course.course_graph or {"children": []}
        
        # Build lookup maps for preservation
        self.existing_modules = {} # normalized_name -> node
        self.existing_topics = {}  # normalized_name -> node (scoped by module?)
        # Actually, let's map by ID if stable, or Name if not.
        # Since Blueprint can act as ID source, we use that. 
        # But we want to preserve the UUIDs generated previously.
        
        self._index_existing_graph()

    def _index_existing_graph(self):
        """Index existing nodes to preserve IDs"""
        if not self.existing_graph:
            return

        children = self.existing_graph.get("children", [])
        for m in children:
            # key by name/title
            m_key = self._normalize(m.get("name"))
            self.existing_modules[m_key] = m
            
            for t in m.get("children", []):
                t_key = f"{m_key}::{self._normalize(t.get('title'))}"
                self.existing_topics[t_key] = t

    def _normalize(self, text: str) -> str:
        return str(text).strip().lower()

    def build(self) -> CourseGraph:
        """
        Builds the CourseGraph structure deterministically from Blueprint.
        """
        blueprint = self.course.blueprint or {}
        new_children: List[ModuleNode] = []
        
        bp_modules = blueprint.get("modules", [])
        
        stats = {"modules_created": 0, "topics_created": 0, "slides_linked": 0}

        for i, mod_data in enumerate(bp_modules):
            m_title = mod_data.get("title", f"Module {i+1}")
            m_key = self._normalize(m_title)
            
            # 1. Resolve Module Node
            existing_mod = self.existing_modules.get(m_key)
            if existing_mod:
                m_node = ModuleNode(
                    id=existing_mod.get("id"),
                    order=existing_mod.get("order", i+1),
                    name=m_title,
                    module_id=str(mod_data.get("id")),
                    ncrf_level=existing_mod.get("ncrf_level")
                )
            else:
                m_node = ModuleNode(
                    order=i+1,
                    name=m_title,
                    module_id=str(mod_data.get("id"))
                )
                stats["modules_created"] += 1

            # 2. Resolve Topics
            bp_topics = mod_data.get("topics", [])
            for j, top_data in enumerate(bp_topics):
                t_title = top_data.get("name", f"Topic {j+1}")
                t_key = f"{m_key}::{self._normalize(t_title)}"
                
                existing_top = self.existing_topics.get(t_key)
                
                if existing_top:
                    t_node = TopicNode(
                        id=existing_top.get("id"),
                        order=existing_top.get("order", j+1),
                        title=t_title,
                        topic_id=str(top_data.get("id"))
                    )
                    # Preserve existing children structure if not overridden?
                    # REQUIREMENT: "If new topic added... appears... without deleting existing slides"
                    # We will re-populate slides from TopicJobs if available (Source of Truth for content)
                    # OR if manual edits happened in Graph, we should prefer Graph?
                    # User Task says: "Input Sources: blueprint, specs, existing slides_json in topic jobs"
                    # So TopicJobs are the content source for now.
                    
                else:
                    t_node = TopicNode(
                        order=j+1,
                        title=t_title,
                        topic_id=str(top_data.get("id"))
                    )
                    stats["topics_created"] += 1

                # 3. Populate Content (Slides) from Job
                # Key: module_id::topic_id
                job_key = f"{m_node.module_id}::{t_node.topic_id}"
                job = self.jobs_map.get(job_key)
                
                if job and job.slides_json:
                    # Convert job slides to Graph Slides
                    slides_data = job.slides_json.get("slides", [])
                    t_node.children = self._convert_slides(slides_data, m_node.module_id, t_node.topic_id, existing_top)
                    stats["slides_linked"] += len(slides_data)
                elif existing_top and existing_top.get("children"):
                    # Fallback: Keep existing graph children if no fresh job info
                    t_node.children = [self._parse_subtopic_or_slide(c) for c in existing_top.get("children", [])]
                # If we rely purely on UUID5(course:module:topic:order), reordering CHANGES the ID.
                # So we need a smarter merge. 
                # Let's pass existing_top to _convert_slides.

                m_node.children.append(t_node)

            new_children.append(m_node)

        # Version handling
        current_ver = self.course.course_graph_version or 0
        
        return CourseGraph(
            course_id=self.course.id,
            version=current_ver + 1,
            children=new_children
        ), stats

    def _convert_slides(self, slides_data: List[dict], module_id: str, topic_id: str, existing_topic_node: dict = None) -> List[SubtopicNode]:
        """
        Convert flat list of slides from Job into Subtopic -> Slide hierarchy.
        Merges with existing IDs if possible.
        """
        # 1. Harvest existing slides to pool
        existing_pool = []
        if existing_topic_node:
            for sub in existing_topic_node.get("children", []):
                for s in sub.get("children", []):
                    existing_pool.append(s)
        
        # 2. Build map by "signature" (Title + First Bullet) to allow reorder stability
        # And map by "Order" as fallback?
        existing_by_sig = {}
        for s in existing_pool:
            # Signature: Title + First 20 chars of first bullet
            bs = s.get("bullets", [])
            b1 = bs[0][:20] if bs else ""
            sig = f"{s.get('title')}::{b1}"
            existing_by_sig[sig] = s.get("id")

        # Create a single "Content" subtopic for now
        sub = SubtopicNode(title="Content", order=1, children=[])
        
        course_id_str = str(self.course.id)
        
        for idx, s in enumerate(slides_data):
            # Try to match existing ID
            bs = s.get("bullets", [])
            b1 = bs[0][:20] if bs else ""
            sig = f"{s.get('title')}::{b1}"
            
            reused_id = existing_by_sig.get(sig)
            
            if reused_id:
                final_id = reused_id
            else:
                # Fallback to deterministic ID (if new slide)
                order = s.get("order", s.get("slide_no", idx+1))
                seed = f"{course_id_str}:{module_id}:{topic_id}:{order}"
                final_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, seed))
            
            slide_node = SlideNode(
                id=final_id,
                title=s.get("title", "Untitled Slide"),
                bullets=s.get("bullets", []),
                speaker_notes=s.get("speaker_notes", ""),
                illustration_prompt=s.get("illustration_prompt", s.get("illustration", "")), 
                order=s.get("order", s.get("slide_no", idx+1)),
                tags={}
            )
            sub.children.append(slide_node)
            
        return [sub]

    def _parse_subtopic_or_slide(self, data: dict):
        # Helper to re-parse existing dict back to pydantic model
        # Try to parse as SubtopicNode
        try:
            return SubtopicNode(**data)
        except:
             return data # Fallback?
